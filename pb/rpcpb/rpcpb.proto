syntax = "proto3";
package rpcpb;

import "github.com/matrixorigin/matrixcube/pb/errorpb/errorpb.proto";
import "github.com/matrixorigin/matrixcube/pb/metapb/metapb.proto";
import "github.com/matrixorigin/matrixcube/pb/txnpb/txnpb.proto";
import "github.com/matrixorigin/matrixcube/pb/hlcpb/timestamp.proto";
import "github.com/gogo/protobuf/gogoproto/gogo.proto";

option (gogoproto.marshaler_all) = true;
option (gogoproto.sizer_all) = true;
option (gogoproto.unmarshaler_all) = true;
option (gogoproto.goproto_enum_prefix_all) = false;

// Type rpc type
enum Type {
    TypeRegisterStore      = 0;
    TypeShardHeartbeatReq  = 1;
    TypeShardHeartbeatRsp  = 2;
    TypeStoreHeartbeatReq  = 3;
    TypeStoreHeartbeatRsp  = 4;
    TypePutStoreReq        = 5;
    TypePutStoreRsp        = 6;
    TypeGetStoreReq        = 7;
    TypeGetStoreRsp        = 8;
    TypeAllocIDReq            = 9;
    TypeAllocIDRsp            = 10;
    TypeAskBatchSplitReq      = 11;
    TypeAskBatchSplitRsp      = 12;
    TypeCreateDestroyingReq   = 13;
    TypeCreateDestroyingRsp   = 14;
    TypeReportDestroyedReq    = 15;
    TypeReportDestroyedRsp    = 16;
    TypeGetDestroyingReq      = 17;
    TypeGetDestroyingRsp      = 18;
    TypeCreateWatcherReq      = 19;
    TypeEventNotify           = 20;
    TypeCreateShardsReq       = 21;
    TypeCreateShardsRsp       = 22;
    TypeRemoveShardsReq       = 23;
    TypeRemoveShardsRsp       = 24;
    TypeCheckShardStateReq    = 25;
    TypeCheckShardStateRsp    = 26;
    TypePutPlacementRuleReq   = 27;
    TypePutPlacementRuleRsp   = 28;
    TypeGetAppliedRulesReq    = 29;
    TypeGetAppliedRulesRsp    = 30;
    TypeCreateJobReq          = 31;
    TypeCreateJobRsp          = 32;
    TypeRemoveJobReq          = 33;
    TypeRemoveJobRsp          = 34;
    TypeExecuteJobReq         = 35;
    TypeExecuteJobRsp         = 36;
    TypeAddScheduleGroupRuleReq  = 37;
    TypeAddScheduleGroupRuleRsp  = 38;
    TypeGetScheduleGroupRuleReq  = 39;
    TypeGetScheduleGroupRuleRsp  = 40;
}

// ProphetRequest the prophet rpc request
message ProphetRequest {
    uint64                id                 = 1  [(gogoproto.customname) = "ID"];
    uint64                storeID            = 2;
    Type                  type               = 3;
    ShardHeartbeatReq     shardHeartbeat     = 4  [(gogoproto.nullable) = false];
    StoreHeartbeatReq     storeHeartbeat     = 5  [(gogoproto.nullable) = false];
    PutStoreReq           putStore           = 6  [(gogoproto.nullable) = false];
    GetStoreReq           getStore           = 7  [(gogoproto.nullable) = false];
    AllocIDReq            allocID            = 8  [(gogoproto.nullable) = false];
    AskBatchSplitReq      askBatchSplit      = 9  [(gogoproto.nullable) = false];
    CreateDestroyingReq   createDestroying   = 10 [(gogoproto.nullable) = false];
    ReportDestroyedReq    ReportDestroyed    = 11 [(gogoproto.nullable) = false];
    GetDestroyingReq      getDestroying      = 12 [(gogoproto.nullable) = false];
    CreateWatcherReq      createWatcher      = 13 [(gogoproto.nullable) = false];
    CreateShardsReq       createShards       = 14 [(gogoproto.nullable) = false];
    RemoveShardsReq       removeShards       = 15 [(gogoproto.nullable) = false];
    CheckShardStateReq    checkShardState    = 16 [(gogoproto.nullable) = false];
    PutPlacementRuleReq   putPlacementRule   = 17 [(gogoproto.nullable) = false];
    GetAppliedRulesReq    getAppliedRules    = 18 [(gogoproto.nullable) = false];
    CreateJobReq          createJob          = 19 [(gogoproto.nullable) = false];
    RemoveJobReq          removeJob          = 20 [(gogoproto.nullable) = false];
    ExecuteJobReq         executeJob         = 21 [(gogoproto.nullable) = false];
    AddScheduleGroupRuleReq         addScheduleGroupRule        = 22 [(gogoproto.nullable) = false];
    GetScheduleGroupRuleReq         getScheduleGroupRule        = 23 [(gogoproto.nullable) = false];
}

// ProphetResponse the prophet rpc response
message ProphetResponse {
    uint64                id                 = 1  [(gogoproto.customname) = "ID"];
    Type                  type               = 2;
    string                error              = 3;
    string                leader             = 4;
    ShardHeartbeatRsp     shardHeartbeat     = 5  [(gogoproto.nullable) = false];
    StoreHeartbeatRsp     storeHeartbeat     = 6  [(gogoproto.nullable) = false];
    PutStoreRsp           putStore           = 7  [(gogoproto.nullable) = false];
    GetStoreRsp           getStore           = 8  [(gogoproto.nullable) = false];
    AllocIDRsp            allocID            = 9  [(gogoproto.nullable) = false];
    AskBatchSplitRsp      askBatchSplit      = 10 [(gogoproto.nullable) = false];
    CreateDestroyingRsp   createDestroying   = 11 [(gogoproto.nullable) = false];
    ReportDestroyedRsp    ReportDestroyed    = 12 [(gogoproto.nullable) = false];
    GetDestroyingRsp      getDestroying      = 13 [(gogoproto.nullable) = false];
    EventNotify           event              = 14 [(gogoproto.nullable) = false];
    CreateShardsRsp       createShards       = 15 [(gogoproto.nullable) = false];
    RemoveShardsRsp       removeShards       = 16 [(gogoproto.nullable) = false];
    CheckShardStateRsp    checkShardState    = 17 [(gogoproto.nullable) = false];
    PutPlacementRuleRsp   putPlacementRule   = 18 [(gogoproto.nullable) = false];
    GetAppliedRulesRsp    getAppliedRules    = 19 [(gogoproto.nullable) = false];
    CreateJobRsp          createJob          = 20 [(gogoproto.nullable) = false];
    RemoveJobRsp          removeJob          = 21 [(gogoproto.nullable) = false];
    ExecuteJobRsp         executeJob         = 22 [(gogoproto.nullable) = false];
    AddScheduleGroupRuleRsp         addScheduleGroupRule        = 23 [(gogoproto.nullable) = false];
    GetScheduleGroupRuleRsp         getScheduleGroupRule        = 24 [(gogoproto.nullable) = false];
}

// ShardHeartbeatReq shard heartbeat request
message ShardHeartbeatReq {
     uint64          storeID     = 1;
     bytes           shard       = 2;
     // Term is the term of raft group.
     uint64          term        = 3;
     metapb.Replica  leader      = 4;
     repeated metapb.ReplicaStats downReplicas    = 5 [(gogoproto.nullable) = false];
     repeated metapb.Replica      pendingReplicas = 6 [(gogoproto.nullable) = false];
     metapb.ShardStats            stats            = 7 [(gogoproto.nullable) = false];
     string                       groupKey         = 8;
     metapb.EpochLease    lease      = 9;
}
   
// ShardHeartbeatRsp shard heartbeat response.
message ShardHeartbeatRsp {
    uint64               shardID      = 1;
    metapb.ShardEpoch shardEpoch   = 2 [(gogoproto.nullable) = false];
    // Leader of the shard at the moment of the corresponding request was made.
    metapb.Replica         targetReplica      = 3;
    // Notice, prophet only allows handling reported epoch >= current prophet's.
    // Leader peer reports shard status with ShardHeartbeatReq
    // to prophet regularly, prophet will determine whether this shard
    // should do ChangePeer or not.
    // E,g, max peer number is 3, shard A, first only peer 1 in A.
    // 1. prophet shard state -> Peers (1), ConfVer (1).
    // 2. Leader peer 1 reports shard state to prophet, prophet finds the
    // peer number is < 3, so first changes its current shard
    // state -> Peers (1, 2), ConfVer (1), and returns ChangePeer Adding 2.
    // 3. Leader does ChangePeer, then reports Peers (1, 2), ConfVer (2),
    // prophet updates its state -> Peers (1, 2), ConfVer (2).
    // 4. Leader may report old Peers (1), ConfVer (1) to pd before ConfChange
    // finished, pd stills responses ChangePeer Adding 2, of course, we must
    // guarantee the second ChangePeer can't be applied in your application.
    ConfigChange         configChange    = 4;
    TransferLeader       transferLeader  = 5;
    Merge                merge           = 6;
    SplitShard           splitShard      = 7;
    ConfigChangeV2       configChangeV2  = 8;
    TransferLease        transferLease   = 9;
    // DestroyDirectly the shard has been removed, destroy directly without raft.
    bool                 destroyDirectly = 10;
}

// PutStoreReq put store request
message PutStoreReq {
    bytes store = 1;
}

// PutStoreRsp put store response
message PutStoreRsp {
    bytes destroyShards = 1;
}

// StoreHeartbeatReq store heartbeat request
message StoreHeartbeatReq {
    metapb.StoreStats stats = 1 [(gogoproto.nullable) = false];
    bytes                 data  = 2;      
}

// StoreHeartbeatRsp store heartbeat response
message StoreHeartbeatRsp {
    bytes                 data  = 1;
}

// GetStoreReq get store request
message GetStoreReq {
    uint64 id = 1 [(gogoproto.customname) = "ID"];
}

// GetStoreRsp get store response
message GetStoreRsp {
    bytes                 data  = 1;
    metapb.StoreStats stats = 2;
}

// AllocIDReq alloc id request
message AllocIDReq {
}

// AllocIDRsp alloc id response
message AllocIDRsp {
    uint64 id = 1 [(gogoproto.customname) = "ID"];
}

// AskBatchSplitReq ask batch split request
message AskBatchSplitReq {
    bytes  data  = 1;
    uint32 count = 2;
}

// AskBatchSplitRsp ask batch split response
message AskBatchSplitRsp {
    repeated SplitID splitIDs = 1 [(gogoproto.nullable) = false];
}


// CreateDestroyingReq create destroying status request
message CreateDestroyingReq {
    uint64            id        = 1 [(gogoproto.customname) = "ID"];
    uint64            index     = 2;
    repeated uint64 replicas    = 3;
    bool             removeData = 4;
}

// CreateDestroyingRsp create destroying status response
message CreateDestroyingRsp {
    metapb.ShardState state = 1;
}

// GetDestroyingReq get destroying status request
message GetDestroyingReq {
    uint64            id        = 1 [(gogoproto.customname) = "ID"];
}

// GetDestroyingRsp get destroying status response
message GetDestroyingRsp {
    metapb.DestroyingStatus status = 1;
}

// ReportDestroyedReq report destroying request
message ReportDestroyedReq {
    uint64            id        = 1 [(gogoproto.customname) = "ID"];
    uint64            replicaID = 2;
}

// ReportDestroyedRsp report destroying rsp
message ReportDestroyedRsp {
    metapb.ShardState state = 1;
}

// SplitID split id
message SplitID {
             uint64 newID      = 1;
    repeated uint64 newReplicaIDs = 2;
}

// CreateWatcherReq create watcher req
message CreateWatcherReq {
    uint32 flag = 1;
}

// CreateShardsReq create shards req
message CreateShardsReq {
    repeated bytes  shards   = 1;
    repeated uint64 leastReplicas  = 2;
}

// CreateShardsRsp create shards rsp
message CreateShardsRsp {
}

// RemoveShardsReq remove shards req
message RemoveShardsReq {
    repeated uint64 ids = 1 [(gogoproto.customname) = "IDs"];
}

// RemoveShardsRsp remove shards rsp
message RemoveShardsRsp {
}

// CheckShardStateReq check shard state req
message CheckShardStateReq {
    bytes ids = 1 [(gogoproto.customname) = "IDs"];
}

// CheckShardStateReq check shard state rsp
message CheckShardStateRsp {
    bytes destroyed  = 1;
    bytes destroying  = 2;
}

// PutPlacementRuleReq put placement rule req
message PutPlacementRuleReq {
    PlacementRule rule = 1 [(gogoproto.nullable) = false];
}

// PutPlacementRuleRsp put placement rule rsp
message PutPlacementRuleRsp {
}

// GetAppliedRulesReq get applied rules req
message GetAppliedRulesReq {
    uint64 shardID = 1;
}

// GetAppliedRulesRsp get applied rules rsp
message GetAppliedRulesRsp {
    repeated PlacementRule rules = 1 [(gogoproto.nullable) = false];
}

// CreateJobReq create job req
message CreateJobReq {
    metapb.Job job = 1 [(gogoproto.nullable) = false];
}

// CreateJobRsp create job rsp
message CreateJobRsp {

}

// RemoveJobReq Remove job req
message RemoveJobReq {
    metapb.Job job = 1 [(gogoproto.nullable) = false];
}

// RemoveJobRsp Remove job rsp
message RemoveJobRsp {

}

// ExecuteJobReq execute on job request
message ExecuteJobReq {
    metapb.Job job  = 1 [(gogoproto.nullable) = false];
    bytes      data = 2;
}

// ExecuteJobRsp execute on job response
message ExecuteJobRsp {
    bytes      data = 1;
}

message AddScheduleGroupRuleReq {
    metapb.ScheduleGroupRule rule = 1 [(gogoproto.nullable) = false];
}

message AddScheduleGroupRuleRsp {

}

message GetScheduleGroupRuleReq {
    
}

message GetScheduleGroupRuleRsp {
    repeated metapb.ScheduleGroupRule rules = 1 [(gogoproto.nullable) = false];
}

// EventNotify event notify
message EventNotify {
    uint64                 seq                 = 1;
    uint32                 type                = 2;
    InitEventData          initEvent           = 3;
    ShardEventData      shardEvent       = 4;
    StoreEventData     storeEvent      = 5;
    metapb.ShardStats   shardStatsEvent  = 6;
    metapb.StoreStats  storeStatsEvent = 7;
}

// InitEventData init event data
message InitEventData {
    repeated bytes  shards            = 1;
    repeated bytes  stores            = 2;
    repeated uint64 leaderReplicaIDs  = 3;
    repeated metapb.EpochLease leases = 4 [(gogoproto.nullable) = false];
}

// ShardEventData shard created or updated
message ShardEventData {
    bytes  data             = 1;
    uint64 leaderReplicaID  = 2;
    metapb.EpochLease lease = 3;
    bool   removed          = 4;
    bool   create           = 5;
}

// StoreEventData store created or updated
message StoreEventData {
    bytes data = 1;
}

// ChangePeer change peer
message ConfigChange {
    metapb.Replica           replica    = 1 [(gogoproto.nullable) = false];
    metapb.ConfigChangeType  changeType = 2;
}

// TransferLeader transfer leader
message TransferLeader {
    metapb.Replica replica = 1 [(gogoproto.nullable) = false];
}

// TransferLease transfer lease
message TransferLease {
    metapb.EpochLease lease = 1 [(gogoproto.nullable) = false];
}

// ConfigChangeV2 change peer v2
message ConfigChangeV2 {
    // If changes is empty, it means that to exit joint state.
    repeated ConfigChange changes = 1 [(gogoproto.nullable) = false];
}

// Merge merge
message Merge {
    // target shard
    bytes target = 1;
}

// SplitShard split shard
message SplitShard {
    metapb.CheckPolicy policy = 1;
    repeated bytes     keys   = 2;
}

// PeerRoleType is the expected peer type of the placement rule
enum ReplicaRoleType {
    // Voter can either match a leader peer or follower peer
    Voter    = 0;
    // Leader matches a leader.
    Leader   = 1;
    // Follower matches a follower.
    Follower = 2;
    // Learner matches a learner.
    Learner  = 3;
}

// LabelConstraintOp defines how a LabelConstraint matches a store. It can be one of
// 'in', 'notIn', 'exists', or 'notExists'.
enum LabelConstraintOp {
    // In If label does not exist, `in` is always false.
    In        = 0;
    // NotIn restricts the store label value should not in the value list.
    NotIn     = 1;
    // Exists restricts the store should have the label.
    Exists    = 2;
    // NotExists restricts the store should not have the label.
    NotExists = 3;
}

// LabelConstraint is used to filter store when trying to place peer of a shard.
message LabelConstraint {
    string            key    = 1;
    LabelConstraintOp op     = 2;
    repeated string   values = 3;
}

// PlacementRule place rule
message PlacementRule {
    // ID unique ID within a group
    string       id       = 1 [(gogoproto.customname) = "ID"];
    // GroupID mark the source that add the rule
    string       groupID  = 2;
    // Index rule apply order in a group, rule with less ID is applied first when indexes are equal
    uint32       index    = 3;
    // Override when it is true, all rules with less indexes are disabled
    bool         override = 4;
    bytes        startKey = 5;
    bytes        endKey   = 6;
    // Role expected role of the peers
    ReplicaRoleType role  = 7;
    // Count expected count of the peers
    uint32       count    = 8;
    // LabelConstraints used to select stores to place peers
    repeated LabelConstraint labelConstraints = 9 [(gogoproto.nullable) = false];
    // LocationLabels used to make peers isolated physically
    repeated string          locationLabels   = 10;
    // IsolationLevelused to isolate replicas explicitly and forcibly
    string                   isolationLevel   = 11;
}

// CmdType command type
enum CmdType {
    // Write write command, need raft consensus
    Write   = 0;
    // Read read command, need raft consensus(read index or lease read)
    Read    = 1;
    // Admin admin command, need raft consensus
    Admin   = 2;
    // Txn reuse ShardsDispatch to forward txn rpc messages  
    Txn     = 3;
}

// InternalCmd internal reserved commands 
enum InternalCmd {
    // CmdConfigChange config change command, admin type
    CmdConfigChange     = 0;
    // CmdCompactLog compact log command, admin type
    CmdCompactLog       = 1;
    // CmdTransferLeader transfer leader command, admin type
    CmdTransferLeader   = 2;
    // CmdBatchSplit batch split command, admin type
    CmdBatchSplit       = 5;
    // CmdUpdateMetadata update shard metadata command, admin type
    CmdUpdateMetadata   = 6;
    // CmdUpdateLabels update shard label command, admin type
    CmdUpdateLabels     = 7;
    // CmdUpdateEpochLease update shard epoch lease
    CmdUpdateEpochLease = 8; 
    // CmdUpdateTxnRecord update txn record command, write type
    CmdUpdateTxnRecord  = 100;
    // CmdDeleteTxnRecord delete txn record command, write type
    CmdDeleteTxnRecord  = 101;
    // CmdCommitTxnData commit txn write data, write type
    CmdCommitTxnData    = 102;
    // CmdRollbackTxnData rollback txn write data, write type
    CmdRollbackTxnData  = 103;
    // CmdCleanTxnMVCCData clean txn mvcc data, write type
    CmdCleanTxnMVCCData = 104;
    // CmdKVSet  kv set command, write type
    CmdKVSet            = 200;
    // CmdKVBatchSet kv batch set command, write type
    CmdKVBatchSet       = 201;
    // CmdKVGet kv get command, read type
    CmdKVGet            = 202;
    // CmdKVBatchGet kv batch get command, read type
    CmdKVBatchGet       = 203;
    // CmdKVDelete kv delete command, write type
    CmdKVDelete         = 204;
    // CmdKVBatchDelete kv batch delete command, write type
    CmdKVBatchDelete    = 205;
    // CmdKVRangeDelete kv range delete command, write type
    CmdKVRangeDelete    = 206;
    // CmdKVScan kv scan command, read type
    CmdKVScan           = 207;
    // CmdKVBatchMixedWrite mixed all kv write request
    CmdKVBatchMixedWrite = 208;
    // CmdReserved cube reserved cmd type value, all custom cmd type read and 
    // write cmd type can not use the value below the reserved value.
    CmdReserved       = 1000;
}

// RequestHeader raft request header, it contains the shard's metadata
message RequestBatchHeader {
    bytes                id               = 1 [(gogoproto.customname) = "ID"];
    uint64               shardID          = 2;
    metapb.Replica       replica          = 3 [(gogoproto.nullable) = false];
    metapb.EpochLease    lease            = 4;
}

message ResponseBatchHeader {
    bytes         id          = 1 [(gogoproto.customname) = "ID"];
    errorpb.Error error       = 2 [(gogoproto.nullable) = false];
}

// RequestBatch we can't include both normal requests and administrator request
// at same time.
message RequestBatch {
    RequestBatchHeader header       = 1 [(gogoproto.nullable) = false];
    repeated Request   requests     = 2 [(gogoproto.nullable) = false];
}

// ResponseBatch response batch
message ResponseBatch {
    ResponseBatchHeader header        = 1 [(gogoproto.nullable) = false];
    repeated Response   responses     = 2 [(gogoproto.nullable) = false];
}

// Request request
message Request {
    bytes   id                                    = 1 [(gogoproto.customname) = "ID"];
    uint64  group                                 = 2;
    CmdType type                                  = 3;
    uint64  customType                            = 4;
    bytes   key                                   = 5;
    bytes   cmd                                   = 6;
    int64   pid                                   = 7 [(gogoproto.customname) = "PID"];
    uint64  toShard                               = 8;
    bool    ignoreEpochCheck                      = 9;
    metapb.ShardEpoch epoch                       = 10 [(gogoproto.nullable) = false];
    // Lease lease at the time of request initiation
    metapb.EpochLease lease                       = 11;
    // KeysRange If the current request operates on multiple Keys, then KeysRange needs 
    // to be filled in, and the client needs to split the request again if it wants to 
    // re-route according to KeysRange after the data management scope of the Shard has 
    // changed, or if it returns the specified error.
    Range   keysRange                              = 12;
    ReplicaSelectPolicy replicaSelectPolicy        = 13;
    // TxnBatchRequest tranasction request if type == Txn
    txnpb.TxnBatchRequest txnBatchRequest          = 14;
    UpdateTxnRecordRequest updateTxnRecord         = 15 [(gogoproto.nullable) = false];
    DeleteTxnRecordRequest      deleteTxnRecord    = 16 [(gogoproto.nullable) = false];
    CommitTxnWriteDataRequest   commitTxnWriteData = 17 [(gogoproto.nullable) = false];
    RollbackTxnWriteDataRequest rollbackTxnRecord  = 18 [(gogoproto.nullable) = false];
    CleanTxnMVCCDataRequest     cleanTxnMVCCData   = 19 [(gogoproto.nullable) = false];
}

// Range key range [from, to)
message Range {
    // From include
    bytes from = 1;
    // To exclude
    bytes to   = 2;
}

// Response response
message Response {
    bytes         id                        = 1 [(gogoproto.customname) = "ID"];
    CmdType       type                      = 2;
    uint64        customType                = 3;
    bytes         value                     = 4;
    int64         pid                       = 5 [(gogoproto.customname) = "PID"];
    errorpb.Error error                     = 6 [(gogoproto.nullable) = false];
    // TxnBatchRequest tranasction request if type == Txn
    txnpb.TxnBatchResponse txnBatchResponse = 7;
    UpdateTxnRecordRequest updateTxnRecord  = 8;
    DeleteTxnRecordRequest deleteTxnRecord  = 9;
    CommitTxnWriteDataRequest commitTxnWriteData  = 10;
    RollbackTxnWriteDataRequest rollbackTxnRecord  = 11;
    CleanTxnMVCCDataRequest cleanTxnMVCCData  = 12;
}

message ConfigChangeRequest {
    // This can be only called in internal RaftStore now.
    metapb.ConfigChangeType changeType = 1;
    metapb.Replica replica = 2 [(gogoproto.nullable) = false];
}

// ConfigChangeResponse change peer response
message ConfigChangeResponse {
    metapb.Shard shard = 1 [(gogoproto.nullable) = false];
}

// CompactLogRequest compact raft log
message CompactLogRequest {
    uint64 compactIndex = 1;
}

// CompactLogResponse compact raft log
message CompactLogResponse {}

// TransferLeaderRequest transfer leader
message TransferLeaderRequest {
    metapb.Replica replica = 1 [(gogoproto.nullable) = false];
}

message TransferLeaderResponse {}

// BatchSplitRequest batch split requests.
message BatchSplitRequest {
    // The requests for splitting a shard into multiple shards.
    // We split Shard A [0, 10) into B [0, 5) and C [5, 10), the len(requests) = 2, and
    // Shard A will not used after split completed.
    repeated SplitRequest requests = 1 [(gogoproto.nullable) = false];
    bytes        context  = 2;
}

message SplitRequest {
    // The start of the sub shard range
    bytes start = 1;
    // The end of the sub shard range
    bytes end   = 2;
    // The new shard id
    uint64 newShardID = 3;
    // The new replicas of the new shard
    repeated metapb.Replica newReplicas = 4 [(gogoproto.nullable) = false];
}

message BatchSplitResponse {
    repeated metapb.Shard shards = 1 [(gogoproto.nullable) = false];
}

message UpdateMetadataRequest {
    metapb.ShardLocalState metadata = 1 [(gogoproto.nullable) = false];
}

message UpdateMetadataResponse {

}

// UpdatePolicy update policy
enum UpdatePolicy {
    // Add add or update
    Add      = 0;
    // Remove remove
    Remove   = 1;
    // Reset reset
    Reset    = 2;
    // Clear clear
    Clear    = 3;
}

message UpdateLabelsRequest {
    repeated metapb.Label labels = 1 [(gogoproto.nullable) = false];
    UpdatePolicy policy = 2;
}

message UpdateLabelsResponse {

}


message UpdateEpochLeaseRequest {
    uint64 shardID = 1;
    metapb.EpochLease lease = 2 [(gogoproto.nullable) = false];
}

message UpdateEpochLeaseResponse {

}

// ReplicaSelectPolicy strategies for selecting replica
enum ReplicaSelectPolicy {
    // SelectLeader select leader replica store
    SelectLeader = 0;
    // SelectRandom select random replica store
    SelectRandom = 1;
    // SelectLeaseHolder select replica lease holder store
    SelectLeaseHolder = 2;
}

// UpdateTxnRecordRequest update txn record request
message UpdateTxnRecordRequest {
    txnpb.TxnRecord txnRecord = 1 [(gogoproto.nullable) = false];
}

// UpdateTxnRecordResponse update txn record response
message UpdateTxnRecordResponse {
    txnpb.TxnRecord txnRecord = 1 [(gogoproto.nullable) = false];
}

// DeleteTxnRecordRequest delete txn record request
message DeleteTxnRecordRequest {
    bytes txnRecordRouteKey = 1;
    bytes txnID             = 2;
}

// DeleteTxnRecordResponse delete txn record response
message DeleteTxnRecordResponse {
}

// CommitTxnWriteDataRequest commit txn write data request
message CommitTxnWriteDataRequest {
    bytes           originKey = 1;
    hlcpb.Timestamp commitTS  = 2 [(gogoproto.nullable) = false];
}

// CommitTxnWriteDataResponse commit txn write data response
message CommitTxnWriteDataResponse {
}

// RollbackTxnWriteDataRequest rollback txn write data request
message RollbackTxnWriteDataRequest {
    bytes           originKey = 1;
    hlcpb.Timestamp timestamp = 2 [(gogoproto.nullable) = false];
}

// RollbackTxnWriteDataResponse rollback txn write data response
message RollbackTxnWriteDataResponse {
}


// CleanTxnMVCCDataRequest clean txn mvcc data request
message CleanTxnMVCCDataRequest {
    hlcpb.Timestamp timestamp  = 1 [(gogoproto.nullable) = false];
}

// CleanTxnMVCCDataResponse clean txn mvcc data response
message CleanTxnMVCCDataResponse {
}

// KVSetRequest kv set request
message KVSetRequest {
    bytes key   = 1;
    bytes value = 2;
}

// KVSetResponse kv set response
message KVSetResponse {

}

// KVBatchSetRequest kv batch set request
message KVBatchSetRequest {
    repeated bytes keys   = 1;
    repeated bytes values = 2;
}

// KVBatchSetResponse kv batch set response
message KVBatchSetResponse {

}

// KVGetRequest kv get request
message KVGetRequest {
    bytes key = 1;
}

// KVGetResponse kv get response
message KVGetResponse {
    bytes value = 1;
}

// KVBatchGetRequest kv batch get request
message KVBatchGetRequest {
    repeated bytes keys = 1;
    // Indexes the original BatchGetRequest may be split and executed on multiple 
    // Shards, and this field indicates the location of these Keys in the original
    // Keys Slice.
    repeated uint64 indexes = 2;
}

// KVBatchGetResponse kv batch get response
message KVBatchGetResponse {
    repeated bytes values = 1;
    repeated uint64 indexes = 2;
}

// KVDeleteRequest kv Delete request
message KVDeleteRequest {
    bytes key = 1;
}

// KVDeleteResponse kv Delete response
message KVDeleteResponse {
}

// KVBatchDeleteRequest kv BatchDelete request
message KVBatchDeleteRequest {
    repeated bytes keys = 1;
}

// KVBatchDeleteResponse kv BatchDelete response
message KVBatchDeleteResponse {
}

// KVRangeDeleteRequest kv RangeDelete request
message KVRangeDeleteRequest {
    // Start include
    bytes start = 1;
    // End exclude
    bytes end   = 2;
}

// KVRangeDeleteResponse kv RangeDelete response
message KVRangeDeleteResponse {
}

// KVScanRequest kv scan request
message KVScanRequest {
    // Start include, not set means min key
    bytes  start      = 1;
    // End exclude, not set means max key
    bytes  end        = 2;
    // Limit maximum count of scanned data
    uint64 limit      = 3;
    // LimitBytes maximum count of scanned data
    uint64 limitBytes = 4;
    // WithValue return the value
    bool   withValue  = 5;
    // OnlyCount only returns count
    bool   onlyCount  = 6;
}

// KVScanResponse kv scan response
message KVScanResponse {
    // Keys scan keys result
    repeated bytes keys   = 1;
    // Values scan values result
    repeated bytes values = 2;
    // Count scan count result
    uint64   count        = 3;
    // Completed true if no data in current shard
    bool     completed    = 4;
    // ShardEnd shard end key
    bytes    shardEnd     = 5;
}


// KVBatchMixedWriteRequest kv batch MixedWrite requests
message KVBatchMixedWriteRequest {
    repeated KVMixedWriteRequest requests = 1 [(gogoproto.nullable) = false];
}

// KVBatchMixedWriteResponse kv batch MixedWrite responses
message KVBatchMixedWriteResponse {
    repeated KVMixedWriteResponse responses = 2 [(gogoproto.nullable) = false];
}

// KVMixedWriteRequest mixed requests
message KVMixedWriteRequest {
    uint64               cmdType     = 1;
    KVSetRequest         set         = 2 [(gogoproto.nullable) = false];
    KVDeleteRequest      delete      = 3 [(gogoproto.nullable) = false];
    KVRangeDeleteRequest rangeDelete = 4 [(gogoproto.nullable) = false];
}

// KVMixedWriteResponse mixed response
message KVMixedWriteResponse {
    uint64               cmdType     = 1;
    KVSetRequest         set         = 2 [(gogoproto.nullable) = false];
    KVDeleteRequest      delete      = 3 [(gogoproto.nullable) = false];
    KVRangeDeleteRequest rangeDelete = 4 [(gogoproto.nullable) = false];
}